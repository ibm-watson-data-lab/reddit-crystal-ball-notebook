{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 2 with Spark 2.0", "name": "python2-spark20"}, "language_info": {"version": "2.7.11", "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}, "cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Reddit Crystal Ball"}, {"metadata": {}, "cell_type": "markdown", "source": "What if there were a way, using Watson Machine Learning and Watson Cognitive Services, to predict the score of a post before putting it on Reddit? Spoiler alert\u200a\u2014\u200athere is!\n\nIn this notebook we'll analyze 7,500 Reddit posts using Spark ML, [Watson ML](https://www.ibm.com/analytics/us/en/watson-data-platform/watson-machine-learning/), and [Watson Tone Analyzer](https://www.ibm.com/watson/services/tone-analyzer/) to predict the best time to submit your post to Reddit. We'll use Spark ML and k-means clustering to train your machine learning model and Watson ML to deploy your model and make predictions using a simple REST API. Finally, we'll run an interactive app directly in this notebook that allows you to predict the success of your Reddit post."}, {"metadata": {}, "cell_type": "markdown", "source": "## Setup\n\n\n### Watson Service setup\n\nIn order to run the Crystal Ball app you need to provision two Watson services in Bluemix:\n\n* Provision a free [Machine Learning service instance](https://console.bluemix.net/catalog/services/machine-learning).\n* Provision a free [Tone Analyzer service instance](https://console.bluemix.net/catalog/services/tone-analyzer).\n\nTake note of the credentials. You will have to enter them later in the notebook.\n\n### Install/upgrade prerequisite libraries\n\nThese first two cells only need to be uncommented and ran once, to set up our environment. We will use [PixieDust](https://github.com/ibm-watson-data-lab/pixiedust) to help visualize our data and to install the [Cloudant](https://www.ibm.com/analytics/us/en/technology/cloud-data-services/cloudant/) Connector to retrieve our Reddit data."}, {"execution_count": null, "cell_type": "code", "source": "#!pip install --upgrade --user pixiedust", "metadata": {"collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "#!pip install watson_developer_cloud", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Uncomment and run the next cell once. This will install the Spark Cloudant Connector. Restart your kernel if instructed to do so."}, {"execution_count": null, "cell_type": "code", "source": "# import pixiedust;pixiedust.installPackage(\"cloudant-labs:spark-cloudant:2.0.0-s_2.11\")", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "This cell imports our dependencies."}, {"execution_count": null, "cell_type": "code", "source": "import pixiedust\nimport pandas as pd\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.clustering import KMeans, KMeansModel\nfrom pyspark.ml.feature import StringIndexer, IndexToString, VectorAssembler\nfrom pyspark.ml.linalg import Vectors\n\nfrom repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact\n\nfrom __future__ import division", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Here is where we define the number of k-means clusters our data will be grouped into. You can experiment with larger or smaller values here to see how it can affect predictions."}, {"execution_count": null, "cell_type": "code", "source": "num_of_clusters = 24", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Load and Explore our Data"}, {"metadata": {}, "cell_type": "markdown", "source": "With our data stored in a Cloudant database and the necessary packages installed, it becomes very simple to load our JSON data straight into a Spark DataFrame."}, {"execution_count": null, "cell_type": "code", "source": "# read-only credentials for training dataset\ncredentials_1 = {\n  'host':'opendata.cloudant.com',\n  'port':'443',\n  'url':'https://opendata.cloudant.com'\n}\n\nspark_session = SparkSession.builder \\\n                    .config(\"cloudant.host\", credentials_1['host']) \\\n                    .config(\"jsonstore.rdd.partitions\", \"1\") \\\n                    .getOrCreate()\ndf = spark_session.read.format(\"com.cloudant.spark\").load(\"reddit_crystal_ball\")", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Using PixieDust's `display()` function and the Dataframe method printSchema() we can look at the structure of our data. You will notice that this data has already been analyzed by Watson Tone Analyzer and includes fields like Agreeableness and Openness. We are using the social tones available in Watson Tone Analyzer."}, {"execution_count": null, "cell_type": "code", "source": "display(df)", "metadata": {"collapsed": true, "pixiedust": {"displayParams": {"rowCount": "500", "handlerId": "dataframe", "keyFields": "subreddit", "aggregation": "SUM", "valueFields": "score"}}}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "df.printSchema()", "metadata": {"collapsed": true, "scrolled": false}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Create our Pipeline and Model"}, {"metadata": {}, "cell_type": "markdown", "source": "One of the features we use to train our model is the subreddit of the post. Subreddit is a string. In order to use it as a feature we must convert it to a numeric value. Here we use a StringIndexer to do so. We then use a Vector Assembler to select only the features we'll need to create our clusters."}, {"execution_count": null, "cell_type": "code", "source": "indexer_subreddit = StringIndexer(inputCol=\"subreddit\", outputCol=\"subreddit_num\")\nassembler = VectorAssembler(inputCols=[\"hour_posted\", \"subreddit_num\", \"avg_word_size\", \"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional Range\"], outputCol=\"features\")", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Here we use [K-Means](https://en.wikipedia.org/wiki/K-means_clustering) to put all of our training data into clusters, which forms the basis for our prediction engine."}, {"execution_count": null, "cell_type": "code", "source": "kmeans = KMeans()\\\n    .setK(num_of_clusters)\\\n    .setSeed(1)\\\n    .setFeaturesCol(\"features\")\\\n    .setPredictionCol(\"prediction\")\npipeline = Pipeline(stages=[indexer_subreddit, assembler, kmeans])\nmodel_km = pipeline.fit(df)", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Once our data has been processed through the Pipeline, the features assembled into a Vector, and having a 'label' column set, we run our entire dataset through the model to predict the cluster for each Reddit post."}, {"execution_count": null, "cell_type": "code", "source": "df_predictions = model_km.transform(df).select([\"_id\", \"hour_posted\", \"subreddit\", \"score\", \"selfText\", \"avg_word_size\", \"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional Range\"]).withColumnRenamed('_id', 'label')\ndf_predictions = df_predictions.rdd.toDF()\ndf_with_predict_col = model_km.transform(df).select([\"_id\", \"hour_posted\", \"subreddit\", \"score\", \"selfText\", \"avg_word_size\", \"Openness\", \"Conscientiousness\", \"Extraversion\", \"Agreeableness\", \"Emotional Range\", \"prediction\"]).withColumnRenamed('_id', 'label')", "metadata": {"collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "df_predictions.printSchema()", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Predict Locally"}, {"metadata": {}, "cell_type": "markdown", "source": "Our model is ready to be published on Watson ML and used to make predictions. Before we publish our model we'll run some predictions locally using sample input."}, {"execution_count": null, "cell_type": "code", "source": "def get_prediction(hour_posted, subreddit, self_text, avg_word_size, openness, conscientiousness, extraversion, agreeableness, emotional_range):\n    df_req = spark.createDataFrame([(hour_posted, subreddit, self_text, avg_word_size, openness, conscientiousness, extraversion, agreeableness, emotional_range)], ['hour_posted', 'subreddit', 'selfText', 'avg_word_size' , 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional Range'])\n    df_res = model_km.transform(df_req)\n    return df_res.select(\"prediction\").rdd.take(1)[0].prediction", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "At this point our prediction function is only returning a cluster number. We will do some further analysis our clusters later to gain more insight from this."}, {"execution_count": null, "cell_type": "code", "source": "get_prediction(17, 'gaming', 'here is my sample text. Gaming sure is more fun with friends, so lets play together!', 2.1, 0.693473, 0.004367, 0.26794, 0.229841, 0.393668)", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Save our Model to Watson ML"}, {"metadata": {}, "cell_type": "markdown", "source": "To deploy the model to Watson ML you will need to have a <a href=\"https://console.bluemix.net/catalog/services/machine-learning\">Watson ML Service provisioned in Bluemix</a>. Fill in your Watson ML credentials here."}, {"execution_count": null, "cell_type": "code", "source": "# @hidden_cell\n# TODO: Add your Watson ML user name, password and instance id information.\nml_creds = {\n  \"url\": \"https://ibm-watson-ml.mybluemix.net\",\n  \"username\": \"\",\n  \"password\": \"\",\n  \"instance_id\": \"\"\n}", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The first step when working with the Watson Machine Learning REST API is to generate an access token."}, {"execution_count": null, "cell_type": "code", "source": "import urllib3, requests, json\n\nheaders = urllib3.util.make_headers(basic_auth='{}:{}'.format(ml_creds['username'], ml_creds['password']))\nurl = '{}/v3/identity/token'.format(ml_creds['url'])\nresponse = requests.get(url, headers=headers)\nmltoken = json.loads(response.text).get('token')", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The name we specify in this next cell will be saved with the model on the Watson ML service."}, {"execution_count": null, "cell_type": "code", "source": "ml_repository_client = MLRepositoryClient(ml_creds['url'])\nml_repository_client.authorize(ml_creds['username'], ml_creds['password'])\nml_repository_name = '7.5K Reddit Posts - (%d clusters)' % num_of_clusters", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "In this next step, we use our model and training data to save a model on Watson ML with the name specified in the previous cell."}, {"execution_count": null, "cell_type": "code", "source": "model_artifact = MLRepositoryArtifact(model_km, training_data=df_predictions, name=ml_repository_name)", "metadata": {"collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "saved_model = ml_repository_client.models.save(model_artifact)", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We can look at the props for our saved model to verify everything was saved properly."}, {"execution_count": null, "cell_type": "code", "source": "print \"modelType: \" + saved_model.meta.prop(\"modelType\")\nprint \"trainingDataSchema: \" + json.dumps([x['name'] for x in saved_model.meta.prop(\"trainingDataSchema\")['fields']], indent=2)\nprint \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\nprint \"UID:\" + saved_model.uid\nprint \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Load our Remotely Saved Model"}, {"metadata": {}, "cell_type": "markdown", "source": "A model saved on Watson ML can be retrieved by its UID. We can then print the name of the model that was loaded to ensure we have the correct one."}, {"execution_count": null, "cell_type": "code", "source": "loadedModelArtifact = ml_repository_client.models.get(saved_model.uid)\nprint str(loadedModelArtifact.name)", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Optional: Deleting Previously Deployed and/or Published Models\nWhen using a trial Bluemix account, there is a limit on the number of models that can be deployed and/or published at one time. If you've reached this limit, you will get errors when trying to deploy or publish additional models."}, {"metadata": {}, "cell_type": "markdown", "source": "**Caution:** Run this next cell to delete any previous deployments for the model currently being worked on in the notebook."}, {"execution_count": null, "cell_type": "code", "source": "ml_models = ml_repository_client.models.all()\nfor ml_model in ml_models:\n    if ml_model.name == ml_repository_name:\n        deployment_header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\n        deployment_url = ml_creds['url'] + \"/v3/wml_instances/\" + ml_creds['instance_id'] + \"/published_models/\" + ml_model.uid + \"/deployments/\"\n        deployment_response = requests.get(deployment_url, headers=deployment_header)\n        o = json.loads(deployment_response.text)\n        if 'resources' in o.keys():\n            for resource in o['resources']:\n                deployment_url = ml_creds['url'] + \"/v3/wml_instances/\" + ml_creds['instance_id'] + \"/published_models/\" + ml_model.uid + \"/deployments/\" + resource['metadata']['guid']\n                # delete the deployments\n                deployment_response = requests.delete(deployment_url, headers=deployment_header)\n                print deployment_response.text", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**Caution:** Run this next cell to delete any published models with the current model name (not including the current one)."}, {"execution_count": null, "cell_type": "code", "source": "delete_published = False\n\n# UNCOMMENT NEXT LINE TO TRIGGER DELETION\n# delete_published = True\n\nif delete_published == True:\n    ml_models = ml_repository_client.models.all()\n    for ml_model in ml_models:\n        if ml_model.name == ml_repository_name:\n            # delete the published models\n            if ml_model.uid != saved_model.uid:\n                ml_repository_client.models.remove(ml_model.uid)", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Now that we have everything we need, we can move to deploying our model and creating a scoring endpoint."}, {"metadata": {}, "cell_type": "markdown", "source": "## Deploy Model with Watson ML\nIn this section you will learn how to create a deployment and a new scoring endpoint for your model in the Watson Machine Learning REST API. \n\nFor more information about the REST API, see the [Watson Machine Learning API Documentation](http://watson-ml-api.mybluemix.net/)."}, {"metadata": {}, "cell_type": "markdown", "source": "First, let's display the current models associated with this Watson ML instance. The next cell will retrive the URL that we can query to find the list of models. The subsequent cell will query that URL and display the models."}, {"execution_count": null, "cell_type": "code", "source": "endpoint_instance = ml_creds['url'] + \"/v3/wml_instances/\" + ml_creds['instance_id']\nheader = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\n\nresponse_get_instance = requests.get(endpoint_instance, headers=header)\nendpoint_published_models = json.loads(response_get_instance.text).get('entity').get('published_models').get('url')\n\nprint endpoint_published_models", "metadata": {"collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\n\nresponse_get_published = requests.get(endpoint_published_models, headers=header)\npublished_model_list = [{'name': x['entity']['name'], 'deployment_url': x['entity']['deployments']['url'], 'guid': x['metadata']['guid']} for x in json.loads(response_get_published.text)['resources']]\n\nfor model in published_model_list:\n    print 'Name: ' + model['name']\n    print 'GUID: ' + model['guid']\n    print 'Deployments URL: ' + model['deployment_url']\n    print '\\n'\n    ", "metadata": {"collapsed": true, "scrolled": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Here we extract the deployment URL for our current working model by looking for the saved model's UID. We'll use this URL to create a new deployment and scoring endpoint on Watson ML."}, {"execution_count": null, "cell_type": "code", "source": "endpoint_deployment = [x['deployment_url'] for x in published_model_list if x['guid'] == saved_model.uid][0]\nif endpoint_deployment:\n    print endpoint_deployment\nelse:\n    print 'no deployment url found for this model'", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We now have the information we need to create our **Scoring Endpoint**, a publicly accessible URL that we can use to make predictions in our app. Here we create a new deployment and extract the scoring endpoint."}, {"execution_count": null, "cell_type": "code", "source": "payload_online = {\"name\": \"7.5K Reddit Posts - (24 clusters)\", \"description\": \"Our Deployed Model\", \"type\": \"online\"}\nresponse_online = requests.post(endpoint_deployment, json=payload_online, headers=header)\nscoring_endpoint = json.loads(response_online.text).get('entity').get('scoring_url')\n\nprint scoring_endpoint", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "To confirm our Scoring Endpoint is active and online, this cell will output all current deployments for the model we've created."}, {"execution_count": null, "cell_type": "code", "source": "endpoint_online = ml_creds['url'] + \"/v3/wml_instances/\" + \\\nml_creds['instance_id'] + \"/published_models/\" + saved_model.uid + \"/deployments\"\nheader_online = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\nresponse = requests.get(endpoint_online, headers=header_online)\n\nendpoint_list = []\n\nfor deployment in json.loads(response.text)['resources']:\n    endpoint = {}\n    endpoint['Deployment'] = deployment['entity']['name'] + ' / ' + deployment['entity']['description']\n    endpoint['Created_at'] = deployment['metadata']['created_at']\n    endpoint['Status'] = deployment['entity']['status']\n    endpoint['Scoring_URL'] = deployment['entity']['scoring_url']\n    endpoint_list.append(endpoint)\n    \n    print json.dumps(endpoint, indent=2, sort_keys=True)\n    print '\\n'", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Finally, we'll sort the _active endpoints_ (in case there is more than one) to confirm we're working with the most current version of our model."}, {"execution_count": null, "cell_type": "code", "source": "active_endpoints = [x for x in endpoint_list if x['Status'] == 'ACTIVE']\nactive_endpoints.sort(key=lambda x: x['Created_at'])\nscoring_url = active_endpoints[-1]['Scoring_URL']\n\nprint scoring_url", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "Now, using a POST request, we can send new information to our scoring endpoint to make predictions. To do that, execute the following sample code: "}, {"execution_count": null, "cell_type": "code", "source": "payload_scoring = {\"fields\": ['hour_posted', 'subreddit', 'selfText', 'avg_word_size' , 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional Range'],\"values\": [[17, 'gaming', 'here is my sample text. Gaming sure is more fun with friends, so lets play together!', 2.1, 0.693473, 0.004367, 0.26794, 0.229841, 0.393668]]}\nresponse_scoring = requests.post(scoring_url, json=payload_scoring, headers=header)\n\nprint response_scoring.text", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The last item in the \"values\" list is our prediction (cluster number) from the scoring endpoint."}, {"execution_count": null, "cell_type": "code", "source": "scoring_endpoint_prediction = response_scoring.json()['values'][0][-1]\nprint scoring_endpoint_prediction", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Understanding our Prediction"}, {"metadata": {}, "cell_type": "markdown", "source": "If you recall we ran our entire dataset through the model to determine the cluster for each post. That was stored in a dataframe called **df_with_predict_col**. Here we register our prediction dataframe as a temporary table and use a SQL query to compute the average score for posts in each cluster. We can then sort and group those clusters into High, Medium, Low, and Great! segments."}, {"execution_count": null, "cell_type": "code", "source": "df_with_predict_col.registerTempTable('predictions')\nclusters_df = spark.sql('SELECT prediction, AVG(score) as cluster_avg_score, COUNT(prediction) as posts_in_cluster FROM predictions GROUP BY prediction')\nspark.catalog.dropTempView('predictions')\ndisplay(clusters_df)", "metadata": {"collapsed": true, "pixiedust": {"displayParams": {"handlerId": "dataframe"}}, "scrolled": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "pandas_scores = clusters_df.toPandas()\ncluster_scores = {int(row.prediction): row.cluster_avg_score for col, row in list(pandas_scores.iterrows())}\nprint(cluster_scores)", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "This function will group our clusters into the 4 score segments based on the number of clusters we used in our model."}, {"execution_count": null, "cell_type": "code", "source": "def get_cluster_groups(num_clusters, scores_list):\n    clusters_per_group = int(num_of_clusters / 4)\n    sorted_clusters = sorted(scores_list, key=scores_list.get)\n    low = sorted_clusters[:clusters_per_group]\n    med = sorted_clusters[clusters_per_group:clusters_per_group*2]\n    high = sorted_clusters[clusters_per_group*2:clusters_per_group*3]\n    great = sorted_clusters[clusters_per_group*3:]\n    return [low, med, high, great]", "metadata": {"collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "cluster_groups = get_cluster_groups(num_of_clusters, cluster_scores)\nprint 'sorted clusters: ' + str(cluster_groups)\nprint 'first group (Low): ' + str(cluster_groups[0])\nprint 'second group (Medium): ' + str(cluster_groups[1])\nprint 'third group (High): ' + str(cluster_groups[2])\nprint 'fourth group (Great!): ' + str(cluster_groups[3])", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Finally, we define another function to output the string representation of the score segment our prediction belongs to."}, {"execution_count": null, "cell_type": "code", "source": "def get_cluster_group_result(cluster_group_list, prediction):\n    idx = 0\n    result = ['Low', 'Medium', 'High', 'Great!']\n    for group in cluster_group_list:\n        if prediction in group:\n            return result[idx]\n        idx += 1\n    return 'Error: No result found.'", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We can now categorize the prediction we made using Watson ML"}, {"execution_count": null, "cell_type": "code", "source": "get_cluster_group_result(cluster_groups, scoring_endpoint_prediction)", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Interact with our Model in a PixieApp"}, {"metadata": {}, "cell_type": "markdown", "source": "To run our PixieApp, we'll need to import a few more Python Libraries."}, {"execution_count": null, "cell_type": "code", "source": "from pixiedust.display.app import *\nfrom watson_developer_cloud import ToneAnalyzerV3\nfrom time import localtime, strftime\nfrom stop_words import get_stop_words\nimport urllib3, requests, json", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Next, you'll have to provision a free <a href=\"https://console.bluemix.net/catalog/services/tone-analyzer\">Watson Tone Analyzer service instance on Bluemix</a> and fill in the service credentials to analyze your input."}, {"execution_count": null, "cell_type": "code", "source": "# @hidden_cell\n# TODO: Add your Watson Tone Analyzer credentials\ntone_creds = {\n  \"username\": \"\",\n  \"password\": \"\"\n}", "metadata": {"collapsed": true}, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "You are ready to load and run the Crustal Ball app."}, {"execution_count": null, "cell_type": "code", "source": "@PixieApp\nclass watson_ml_reddit:\n    #------------------------------ UTILITY METHODS ------------------------------#\n    def process_input_tone(self):\n        tone_analyzer = ToneAnalyzerV3(\n            username = tone_creds['username'],\n            password = tone_creds['password'],\n            version = '2016-05-19')\n        return [tone['score'] for tone in tone_analyzer.tone(self.text_body, tones=\"social\", sentences='False')['document_tone']['tone_categories'][0]['tones']]\n    def am_pm(self):\n        base_hour = int(strftime(\"%H\", localtime()))\n        rounded_hour = base_hour + 1 if int(strftime(\"%H\", localtime())) >= 30 else base_hour\n        return 'AM' if rounded_hour < 12 else 'PM'\n    def get_watson_deployed_prediction(self, hour_posted, subreddit, avg_word_size, openness, conscientiousness, extraversion, agreeableness, emotional_range):\n        header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + self.token}\n        payload_scoring = {\"fields\": ['hour_posted', 'subreddit', 'selfText', 'avg_word_size' , 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional Range'], \\\n                           \"values\": [[hour_posted, subreddit, self.text_body, avg_word_size, openness, conscientiousness, extraversion, agreeableness, emotional_range]]}\n        while True:\n            try:\n                response_scoring = dict(requests.post(scoring_url, json=payload_scoring, headers=header).json())\n                prediction = response_scoring.get('values')[0][-1]\n                break\n            except:\n                pass\n        return prediction\n    def generate_ml_token(self):\n        headers = urllib3.util.make_headers(basic_auth='{}:{}'.format(ml_creds['username'], ml_creds['password']))\n        url = '{}/v3/identity/token'.format(ml_creds['url'])\n        response = requests.get(url, headers=headers)\n        return json.loads(response.text).get('token')\n    def get_cluster_groups(self):\n        clusters_per_group = int(num_of_clusters / 4)\n        sorted_clusters = sorted(self.cluster_scores, key=self.cluster_scores.get)\n        low = sorted_clusters[:clusters_per_group]\n        med = sorted_clusters[clusters_per_group:clusters_per_group * 2]\n        high = sorted_clusters[clusters_per_group * 2:clusters_per_group * 3]\n        great = sorted_clusters[clusters_per_group * 3:]\n        return [low, med, high, great]\n    def get_result_from_cluster_group(self, prediction):\n        idx = 0\n        result = ['Low', 'Medium', 'High', 'Great!']\n        for group in self.cluster_groups:\n            if prediction in group:\n                return result[idx]\n            idx += 1\n        return '!! Error !!'\n    def get_num_score(self, label):\n        score_map = {'Low': 0, 'Medium': 1, 'High': 2, 'Great!': 3, '!! Error !!': -1}\n        return score_map[label]\n    def get_score_color(self, score):\n        if score == 'Great!':\n            color = '#00FF00'\n        elif score == 'High':\n            color = 'green'\n        elif score == 'Medium':\n            color = 'orange'\n        elif score == 'Low':\n            color = 'red'\n        else:\n            color = 'gray'\n        return color\n    def get_current_hour(self):\n        base_hour = int(strftime(\"%H\", localtime()))\n        rounded_hour = base_hour + 1 if int(strftime(\"%H\", localtime())) >= 30 else base_hour\n        return rounded_hour\n    def get_next_great_time(self):\n        next_hour = self.get_current_hour()\n        best_time = -1\n        current_score = ''\n        if self.result != 'Great!':\n            current_score = self.result\n            while current_score != 'Great!' and next_hour < 23:\n                next_hour = next_hour + 1        \n                new_score = self.get_result_from_cluster_group(self.get_watson_deployed_prediction(next_hour, self.subreddit, self.word_size, *self.tone_list))\n                if self.get_num_score(new_score) > self.get_num_score(current_score):\n                    self.better_score = new_score\n                    current_score = new_score\n                    best_time = next_hour\n        return best_time\n    def get_avg_word_size(self):\n        my_stopwords = get_stop_words('english')\n        word_lengths = [int(len(word)) for word in self.text_body.split(\" \") if not word in my_stopwords]\n        return pd.Series(word_lengths).sum()/len(word_lengths)\n    def convert_time_output(self, hour):\n        if int(hour) == 0:\n            return \"12 AM\"\n        elif int(hour) < 12:\n            return \"{} AM\".format(hour)\n        elif int(hour) == 12:\n            return \"12 PM\"\n        else:\n            return \"{} PM\".format(hour-12)\n    #-------------------------- DYNAMIC CONTENT METHODS --------------------------#\n    def generate_result(self):\n        output = \"\"\"\n        <div id=\"result-div\">\n            <div class=\"row\">\n                <h3>Your post: </h3>\n                <div id=\"post-container\">\n                    <p style=\"margin: 0 auto 0 auto; display: inline;\">{0}</p>\n                </div>\n            </div>\n            <div class=\"row\" style=\"margin-top: 40px; margin-bottom: 10px;\">\n                <h3>Should get a <span style=\"color: {4};\">{2}</span> score when posted at {3} in r/{1}.</h3>\n            </div>\n        \"\"\".format(self.text_body, self.subreddit, self.result, self.convert_time_output(self.hour), self.get_score_color(self.result)) + \\\n        self.generate_future_score_msg(self.get_next_great_time()) + \"\"\"\n            <div class=\"row\" style=\"margin: 40px auto 5px auto;\">\n                <h3>Social Tone analysis of your post:</h3>\n                <table style=\"margin: 10px auto 0 auto;\">\n                    <tr>\n                        <th>Openness</th>\n                        <th>Conscientiousness</th>\n                        <th>Extraversion</th>\n                        <th>Agreeableness</th>\n                        <th>Emotional Range</th>\n                    </tr>\n                    <tr>\n                        <td>{0}</td>\n                        <td>{1}</td>\n                        <td>{2}</td>\n                        <td>{3}</td>\n                        <td>{4}</td>\n                    </tr>\n                </table>\n            </div>\n        \"\"\".format(*self.tone_list) + \"\"\"\n        </div>\n        \"\"\"\n        return output\n    def generate_future_score_msg(self, time):\n        if time == -1:\n            return \"\"\"<h3><span style=\"color: {0};\">{1}</span> is the highest score your post will receive for the rest of the day.</h3>\"\"\".format(self.get_score_color(self.result), self.result)\n        else: \n            return \"\"\"<h3>You could get a <span style=\"color: {0};\">{1}</span> score at {2}. You may want to wait until then to make your post.</h3>\"\"\".format(self.get_score_color(self.better_score), self.better_score, self.convert_time_output(time))\n    #------------------------------- ROUTES/VIEWS --------------------------------#\n    @route()\n    def default_route(self):\n        self.token = self.generate_ml_token()\n        self.cluster_scores = cluster_scores\n        self.cluster_groups = self.get_cluster_groups()\n        return \"\"\"\n            <div class=\"row text-center\">\n                <h2>Reddit Comment Karma</h2> \n                <h2 style=\"margin-top:8px\">Crystal Ball</h2>\n                <h3 style=\"color:gray;\">Powered by Watson ML</h3>\n                <button \n                        type=\"submit\" \n                        style=\"margin-top: 15px;\"\n                        pd_options=\"view=input_post\"\n                        class=\"btn btn-success\">Start\n                </button>    \n            </div>\n        \"\"\"\n    @route(view=\"input_post\")\n    def input_post(self):\n        return \"\"\"\n            <style>\n                #sub_list {\n                    margin: 0 auto 0 0;\n                    max-width: 60%;\n                }\n                #hour_list {\n                    display: inline;\n                    margin: 15px auto 15px 0;\n                    max-width: 10%;\n                }\n                #am_pm {\n                    max-width: 8%;\n                    display: inline;\n                }\n                h3 {\n                    display: inline;\n                }\n                #text_input {\n                    border-radius: 5px;\n                    max-width: 72%;\n                    float: left;\n                }\n            </style>\n            <div class=\"row\">\n                <h3 style=\"margin-bottom:20px;\">Enter the details of your post...</h3>\n            </div>\n            <div class=\"row\">\n                <form class=\"horizontal\">\n                    <div class=\"form-group\">\n                        <label for=\"sub_list\" class=\"col-sm-2 control-label\">Choose Subreddit:</label>\n                        <select class=\"form-control\" id=\"sub_list\">\n                            <option>gaming</option>                            \n                            <option>science</option>\n                            <option>space</option>\n                            <option>learnprogramming</option>\n                            <option>MachineLearning</option>\n                        </select>\n                    </div>\n                </form>\n\n                <form class=\"horizontal\">\n                    <div class=\"form-group\">\n                        <label for=\"text_input\" class=\"col-sm-2 control-label\">Post Body:</label>\n                        <div class=\"col-sm-10\">\n                            <textarea \n                                id=\"text_input\"\n                                rows=\"3\"\n                                class=\"form-control\"\n                            />\n                        </div>\n                    </div>\n                </form>\n                <div class=\"row\">\n                    <div class=\"col-sm-offset-2\">\n                        <button \n                            type=\"submit\" \n                            style=\"margin-top: 10px;\"\n                            pd_options=\"view=view_result\"\n                            pd_script=\"self.text_body='''$val(text_input)'''\\nself.subreddit='''$val(sub_list)'''\\nself.hour=self.get_current_hour()\\nself.tone_list=self.process_input_tone()\\nself.word_size=self.get_avg_word_size()\\nself.result=self.get_result_from_cluster_group(self.get_watson_deployed_prediction(self.get_current_hour(), self.subreddit, self.word_size, *self.tone_list))\\nself.next_time=self.get_next_great_time()\" \n                            class=\"btn btn-success\">Analyze\n                        </button>\n                    </div>\n                </div>\n            </div>\n        \"\"\"\n    @route(view=\"result_preview\")\n    def result_preview(self):\n        return \"\"\"\n            <pre>Subreddit: {0}</pre>\\n<pre>Text: {1}</pre><pre>{2}</pre><pre>{3}</pre><pre>the next best time to post would be {4}.</pre>\n        \"\"\".format(self.subreddit, self.text_body, json.dumps(self.tone_list, indent=2), self.get_result_from_cluster_group(int(self.result)), self.convert_time_output(self.next_time))\n    @route(view=\"view_result\")\n    def view_result(self):\n        return \"\"\"\n            <style>\n                #result-div h3 {\n                    display: inline;\n                }\n                #post-container {\n                    background-color: rgb(245,245,245);\n                    width: 35%;\n                    margin: 10px auto 0 auto;\n                    border-radius: 5px;\n                    min-height: 25px;\n                    padding: .75%;\n                }\n            </style>\n            <div class=\"text-center\">\n                <div class=\"row\" style=\"margin-bottom: 20px;\">\n                    <h2 style=\"margin: 0;\">According to Watson...</h2>\n                </div>\n        \"\"\" + self.generate_result() + \\\n        \"\"\"\n                <div class=\"row\">\n                    <button \n                            type=\"submit\" \n                            style=\"margin-top: 15px;\"\n                            pd_options=\"view=input_post\"\n                            class=\"btn btn-primary\">Back\n                    </button>    \n                </div>            \n            </div>\n        \"\"\"\n    @route(view=\"current_time\")\n    def current_time(self):\n        return \"\"\"\n            <div class=\"row\">\n                The current hour, rounded to the nearest hour, in 24 HR format, is {}\n            </div> \n        \"\"\".format(self.get_current_hour())\n", "metadata": {"collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "myApp = watson_ml_reddit()\nmyApp.run()", "metadata": {"collapsed": true}, "outputs": []}], "nbformat": 4, "nbformat_minor": 1}